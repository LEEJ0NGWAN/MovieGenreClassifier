{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5zS2oFMxYPJ",
        "colab_type": "code",
        "outputId": "ce21708c-e477-4146-97c5-12b635f2a62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "!git clone https://github.com/LEEJ0NGWAN/Scene-Sentiment-Classifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Scene-Sentiment-Classifier'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 16883 (delta 11), reused 31 (delta 10), pack-reused 16849\u001b[K\n",
            "Receiving objects: 100% (16883/16883), 2.49 GiB | 15.16 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "Checking out files: 100% (18001/18001), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKGxlI1dxqrg",
        "colab_type": "code",
        "outputId": "707117a1-108e-434c-c7f8-681afe67980d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%cd ./Scene-Sentiment-Classifier/\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Scene-Sentiment-Classifier\n",
            "data  docs  LICENSE  README.md\ttools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoVsgniixrCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm ./data/horror_test/DarkNamer.exe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udu3Fg8GxzGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils import data\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZckgzUixzEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MovieDataLoader(Dataset):\n",
        "    def __init__(self, root_dir, folder_names, mode, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.folder_names = folder_names\n",
        "        self.file_list =[]\n",
        "        for fn in folder_names:\n",
        "            self.total_dir = os.path.join(self.root_dir, fn)\n",
        "            self.file_list += os.listdir(self.total_dir)\n",
        "        self.file_len = len(self.file_list)\n",
        "        self.train_and_test = folder_names[0].split('_')[1]\n",
        "        self.genre = ['action', 'horror', 'romance', 'ani2D', 'ani3D', 'sf']\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.file_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.file_list[idx]\n",
        "        label = img_name.split('_')[0]\n",
        "        image = Image.open(os.path.join(self.root_dir+'/'+label+'_'+self.train_and_test, img_name))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.mode == 'TRAIN':\n",
        "            return image, self.genre.index(label)\n",
        "        elif self.mode == 'TEST':\n",
        "            return image, torch.LongTensor([self.genre.index(label)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG0_uPOIxzBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre = ['action', 'horror', 'romance', 'ani2D', 'ani3D', 'sf']\n",
        "folder_name = []\n",
        "train_and_test = ['train', 'test']\n",
        "folder_name_train = ['action_train', 'horror_train', 'romance_train', 'ani2D_train', 'ani3D_train', 'sf_train']\n",
        "folder_name_test = ['action_test', 'horror_test', 'romance_test', 'ani2D_test', 'ani3D_test', 'sf_test']\n",
        "root_dir = './data'\n",
        "\n",
        "classes = ('action', 'horror', 'romance', 'ani2D', 'ani3D', 'sf')\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    #transforms.Resize(512),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.CenterCrop(224),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "CLASS_LEN = 6\n",
        "BATCH_SIZE = 32\n",
        "PRINT_PER_BATCH = 100\n",
        "MODEL_NAME = 'VGG16'\n",
        "epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bay9_pSVxy--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "train_dataset = MovieDataLoader(root_dir, folder_name_train, 'TRAIN', preprocess )\n",
        "test_dataset = MovieDataLoader(root_dir, folder_name_test ,'TEST',preprocess)\n",
        "train_data_loader = data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
        "test_data_loader = data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
        "\n",
        "net = models.vgg16()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbYTnbyCxy8l",
        "colab_type": "code",
        "outputId": "12c3cc51-264c-4228-b05c-65ab1b929324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "\n",
        "\n",
        "print('\\n===> Training Start')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('\\n===> Training on GPU!')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\n===> epoch %d' % epoch)\n",
        "    running_loss = 0.0\n",
        "    n_train_correct, n_total = 0, 0\n",
        "\n",
        "    for i, data in enumerate(train_data_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_train_correct += (predicted == labels.view(labels.shape[0])).squeeze().sum().item()\n",
        "        n_total += labels.shape[0]\n",
        "        train_acc = 100. * n_train_correct/n_total\n",
        "\n",
        "\n",
        "        if i % PRINT_PER_BATCH == PRINT_PER_BATCH - 1: \n",
        "            print('train: [%d, %5d] loss: %.3f accuracy: %.3f' %\n",
        "                  (epoch + 1, i + 1, loss.item(), train_acc), end = ' ')\n",
        "            running_loss = 0.0\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            train_accuracy.append(train_acc)\n",
        "\n",
        "            net.eval(); \n",
        "\n",
        "            n_test_correct, test_loss = 0, 0\n",
        "            n_test_total = 0\n",
        "            with torch.no_grad():\n",
        "                for j, data in enumerate(test_data_loader):\n",
        "                    images, labels = data\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = net(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    n_test_correct += (predicted == labels.view(labels.shape[0])).squeeze().sum().item()\n",
        "                    n_test_total += labels.shape[0]\n",
        "                    test_loss = criterion(outputs, labels.view(-1))\n",
        "            test_acc = 100. * n_test_correct /  n_test_total\n",
        "\n",
        "            test_losses.append(test_loss.item())\n",
        "            test_accuracy.append(test_acc)\n",
        "\n",
        "            print('test: [%d, %5d] loss: %.3f accuracy: %.3f' %\n",
        "                  (epoch + 1, j + 1, test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===> Training Start\n",
            "\n",
            "===> Training on GPU!\n",
            "\n",
            "===> epoch 0\n",
            "train: [1,   100] loss: 1.514 accuracy: 20.875 test: [1,   132] loss: 1.647 accuracy: 17.723\n",
            "train: [1,   200] loss: 1.294 accuracy: 30.016 test: [1,   132] loss: 1.632 accuracy: 31.467\n",
            "train: [1,   300] loss: 1.015 accuracy: 35.302 test: [1,   132] loss: 1.758 accuracy: 29.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQEa2Rpaxyxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(CLASS_LEN))\n",
        "class_total = list(0. for i in range(CLASS_LEN))\n",
        "with torch.no_grad():\n",
        "    for data in test_data_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        #print(labels.shape)\n",
        "        labels = labels.view(labels.shape[0])\n",
        "        \n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        #print(torch.max(outputs, 1))\n",
        "        #print('predicted', predicted)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        #print('c', c)\n",
        "        for i in range(labels.shape[0]):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I-0ZFtkEWm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"train accuracy: \" + str(max(train_accuracy)))\n",
        "print(\"validation accuracy: \" + str(max(test_accuracy)))\n",
        "\n",
        "per_minibatch = range(PRINT_PER_BATCH, PRINT_PER_BATCH*len(train_losses)+1, PRINT_PER_BATCH)\n",
        "\n",
        "plt.plot(per_minibatch, train_losses, 'r', label='Training loss')\n",
        "plt.plot(per_minibatch, test_losses, 'b', label='validation loss')\n",
        "plt.title(MODEL_NAME + 'Training and validation loss' + '  batch size: ' + str(BATCH_SIZE))\n",
        "plt.xlabel('per minibatches')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(per_minibatch, train_accuracy, 'r', label='Training acc')\n",
        "plt.plot(per_minibatch, test_accuracy, 'b', label='Validation acc')\n",
        "plt.title(MODEL_NAME + 'Training and validation accuracy' + '  batch size: ' + str(BATCH_SIZE))\n",
        "plt.xlabel('per minibatches')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRRAKArzEYmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_per_class = []\n",
        "for i in range(CLASS_LEN):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    acc_per_class.append(100 * class_correct[i] / class_total[i])\n",
        "hist = plt.hist(classes, weights = acc_per_class, color = 'b', linewidth = 1.2)\n",
        "plt.title(MODEL_NAME + ' Accuracy Per Class'+ '  batch size: ' + str(BATCH_SIZE))\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Accuracy(%)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}